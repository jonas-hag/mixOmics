<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>mixOmics vignette</title>
  <meta name="description" content="Vignette for the R package mixOmics">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="mixOmics vignette" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Vignette for the R package mixOmics" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="mixOmics vignette" />
  
  <meta name="twitter:description" content="Vignette for the R package mixOmics" />
  

<meta name="author" content="Kim-Anh Le Cao &amp; Sebastien Dejean">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="pca.html">
<link rel="next" href="pls.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#intro:datatypes"><i class="fa fa-check"></i><b>1.1</b> Input data</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#methods"><i class="fa fa-check"></i><b>1.2</b> Methods</a><ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#intro:background"><i class="fa fa-check"></i><b>1.2.1</b> Some background knowledge</a></li>
<li class="chapter" data-level="1.2.2" data-path="intro.html"><a href="intro.html#intro:overview"><i class="fa fa-check"></i><b>1.2.2</b> Overview</a></li>
<li class="chapter" data-level="1.2.3" data-path="intro.html"><a href="intro.html#intro:pubs"><i class="fa fa-check"></i><b>1.2.3</b> Key publications</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#outline-of-this-vignette"><i class="fa fa-check"></i><b>1.3</b> Outline of this Vignette</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#other-methods-not-covered-in-this-vignette"><i class="fa fa-check"></i><b>1.4</b> Other methods not covered in this vignette</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="start.html"><a href="start.html"><i class="fa fa-check"></i><b>2</b> Let’s get started</a><ul>
<li class="chapter" data-level="2.1" data-path="start.html"><a href="start.html#installation"><i class="fa fa-check"></i><b>2.1</b> Installation</a></li>
<li class="chapter" data-level="2.2" data-path="start.html"><a href="start.html#start:upload"><i class="fa fa-check"></i><b>2.2</b> Load the package</a></li>
<li class="chapter" data-level="2.3" data-path="start.html"><a href="start.html#upload-data"><i class="fa fa-check"></i><b>2.3</b> Upload data</a></li>
<li class="chapter" data-level="2.4" data-path="start.html"><a href="start.html#start:PCA"><i class="fa fa-check"></i><b>2.4</b> Quick start in <code>mixOmics</code></a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>3</b> Principal Component Analysis (PCA)</a><ul>
<li class="chapter" data-level="3.1" data-path="pca.html"><a href="pca.html#biological-question"><i class="fa fa-check"></i><b>3.1</b> Biological question</a></li>
<li class="chapter" data-level="3.2" data-path="pca.html"><a href="pca.html#the-liver.toxicity-study"><i class="fa fa-check"></i><b>3.2</b> The <code>liver.toxicity</code> study</a></li>
<li class="chapter" data-level="3.3" data-path="pca.html"><a href="pca.html#principle-of-pca"><i class="fa fa-check"></i><b>3.3</b> Principle of PCA</a></li>
<li class="chapter" data-level="3.4" data-path="pca.html"><a href="pca.html#load-the-data"><i class="fa fa-check"></i><b>3.4</b> Load the data</a></li>
<li class="chapter" data-level="3.5" data-path="pca.html"><a href="pca.html#quick-start"><i class="fa fa-check"></i><b>3.5</b> Quick start</a></li>
<li class="chapter" data-level="3.6" data-path="pca.html"><a href="pca.html#to-go-further"><i class="fa fa-check"></i><b>3.6</b> To go further</a><ul>
<li class="chapter" data-level="3.6.1" data-path="pca.html"><a href="pca.html#customize-plots"><i class="fa fa-check"></i><b>3.6.1</b> Customize plots</a></li>
<li class="chapter" data-level="3.6.2" data-path="pca.html"><a href="pca.html#amount-of-variance-explained-and-choice-of-number-of-components"><i class="fa fa-check"></i><b>3.6.2</b> Amount of variance explained and choice of number of components</a></li>
<li class="chapter" data-level="3.6.3" data-path="pca.html"><a href="pca.html#other-useful-plots"><i class="fa fa-check"></i><b>3.6.3</b> Other useful plots</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="pca.html"><a href="pca.html#sPCA"><i class="fa fa-check"></i><b>3.7</b> Variable selection with sparse PCA</a><ul>
<li class="chapter" data-level="3.7.1" data-path="pca.html"><a href="pca.html#biological-question-1"><i class="fa fa-check"></i><b>3.7.1</b> Biological question</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="pca.html"><a href="pca.html#tuning-parameters"><i class="fa fa-check"></i><b>3.8</b> Tuning parameters</a></li>
<li class="chapter" data-level="3.9" data-path="pca.html"><a href="pca.html#additional-resources"><i class="fa fa-check"></i><b>3.9</b> Additional resources</a></li>
<li class="chapter" data-level="3.10" data-path="pca.html"><a href="pca.html#faq"><i class="fa fa-check"></i><b>3.10</b> FAQ</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="plsda.html"><a href="plsda.html"><i class="fa fa-check"></i><b>4</b> PLS - Discriminant Analysis (PLS-DA)</a><ul>
<li class="chapter" data-level="4.1" data-path="plsda.html"><a href="plsda.html#biological-question-2"><i class="fa fa-check"></i><b>4.1</b> Biological question</a></li>
<li class="chapter" data-level="4.2" data-path="plsda.html"><a href="plsda.html#the-srbct-study"><i class="fa fa-check"></i><b>4.2</b> The <code>srbct</code> study</a></li>
<li class="chapter" data-level="4.3" data-path="plsda.html"><a href="plsda.html#principle-of-sparse-pls-da"><i class="fa fa-check"></i><b>4.3</b> Principle of sparse PLS-DA</a></li>
<li class="chapter" data-level="4.4" data-path="plsda.html"><a href="plsda.html#inputs-and-outputs"><i class="fa fa-check"></i><b>4.4</b> Inputs and outputs</a></li>
<li class="chapter" data-level="4.5" data-path="plsda.html"><a href="plsda.html#set-up-the-data"><i class="fa fa-check"></i><b>4.5</b> Set up the data</a></li>
<li class="chapter" data-level="4.6" data-path="plsda.html"><a href="plsda.html#quick-start-1"><i class="fa fa-check"></i><b>4.6</b> Quick start</a></li>
<li class="chapter" data-level="4.7" data-path="plsda.html"><a href="plsda.html#plsda-tgf"><i class="fa fa-check"></i><b>4.7</b> To go further</a><ul>
<li class="chapter" data-level="4.7.1" data-path="plsda.html"><a href="plsda.html#splsda:plotIndiv"><i class="fa fa-check"></i><b>4.7.1</b> Customize sample plots</a></li>
<li class="chapter" data-level="4.7.2" data-path="plsda.html"><a href="plsda.html#customize-variable-plots"><i class="fa fa-check"></i><b>4.7.2</b> Customize variable plots</a></li>
<li class="chapter" data-level="4.7.3" data-path="plsda.html"><a href="plsda.html#other-useful-plots-1"><i class="fa fa-check"></i><b>4.7.3</b> Other useful plots</a></li>
<li class="chapter" data-level="4.7.4" data-path="plsda.html"><a href="plsda.html#variable-selection-outputs"><i class="fa fa-check"></i><b>4.7.4</b> Variable selection outputs</a></li>
<li class="chapter" data-level="4.7.5" data-path="plsda.html"><a href="plsda.html#tuning:sPLSDA"><i class="fa fa-check"></i><b>4.7.5</b> Tuning parameters and numerical outputs</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="plsda.html"><a href="plsda.html#additional-resources-1"><i class="fa fa-check"></i><b>4.8</b> Additional resources</a></li>
<li class="chapter" data-level="4.9" data-path="plsda.html"><a href="plsda.html#faq-1"><i class="fa fa-check"></i><b>4.9</b> FAQ</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="pls.html"><a href="pls.html"><i class="fa fa-check"></i><b>5</b> Projection to Latent Structure (PLS)</a><ul>
<li class="chapter" data-level="5.1" data-path="pls.html"><a href="pls.html#biological-question-3"><i class="fa fa-check"></i><b>5.1</b> Biological question</a></li>
<li class="chapter" data-level="5.2" data-path="pls.html"><a href="pls.html#the-nutrimouse-study"><i class="fa fa-check"></i><b>5.2</b> The <code>nutrimouse</code> study</a></li>
<li class="chapter" data-level="5.3" data-path="pls.html"><a href="pls.html#principle-of-pls"><i class="fa fa-check"></i><b>5.3</b> Principle of PLS</a></li>
<li class="chapter" data-level="5.4" data-path="pls.html"><a href="pls.html#principle-of-sparse-pls"><i class="fa fa-check"></i><b>5.4</b> Principle of sparse PLS</a></li>
<li class="chapter" data-level="5.5" data-path="pls.html"><a href="pls.html#inputs-and-outputs-1"><i class="fa fa-check"></i><b>5.5</b> Inputs and outputs</a></li>
<li class="chapter" data-level="5.6" data-path="pls.html"><a href="pls.html#set-up-the-data-1"><i class="fa fa-check"></i><b>5.6</b> Set up the data</a></li>
<li class="chapter" data-level="5.7" data-path="pls.html"><a href="pls.html#quick-start-2"><i class="fa fa-check"></i><b>5.7</b> Quick start</a></li>
<li class="chapter" data-level="5.8" data-path="pls.html"><a href="pls.html#pls-tgf"><i class="fa fa-check"></i><b>5.8</b> To go further</a><ul>
<li class="chapter" data-level="5.8.1" data-path="pls.html"><a href="pls.html#pls:plotIndiv"><i class="fa fa-check"></i><b>5.8.1</b> Customize sample plots</a></li>
<li class="chapter" data-level="5.8.2" data-path="pls.html"><a href="pls.html#pls:plotVar"><i class="fa fa-check"></i><b>5.8.2</b> Customize variable plots</a></li>
<li class="chapter" data-level="5.8.3" data-path="pls.html"><a href="pls.html#other-useful-plots-for-data-integration"><i class="fa fa-check"></i><b>5.8.3</b> Other useful plots for data integration</a></li>
<li class="chapter" data-level="5.8.4" data-path="pls.html"><a href="pls.html#variable-selection-outputs-1"><i class="fa fa-check"></i><b>5.8.4</b> Variable selection outputs</a></li>
<li class="chapter" data-level="5.8.5" data-path="pls.html"><a href="pls.html#tuning:PLS"><i class="fa fa-check"></i><b>5.8.5</b> Tuning parameters and numerical outputs</a></li>
<li class="chapter" data-level="5.8.6" data-path="pls.html"><a href="pls.html#PLS:details"><i class="fa fa-check"></i><b>5.8.6</b> PLS modes</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="pls.html"><a href="pls.html#additional-resources-2"><i class="fa fa-check"></i><b>5.9</b> Additional resources</a></li>
<li class="chapter" data-level="5.10" data-path="pls.html"><a href="pls.html#faq-2"><i class="fa fa-check"></i><b>5.10</b> FAQ</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="diablo.html"><a href="diablo.html"><i class="fa fa-check"></i><b>6</b> Multi-block Discriminant Analysis with DIABLO</a><ul>
<li class="chapter" data-level="6.1" data-path="diablo.html"><a href="diablo.html#biological-question-4"><i class="fa fa-check"></i><b>6.1</b> Biological question</a></li>
<li class="chapter" data-level="6.2" data-path="diablo.html"><a href="diablo.html#the-breast.tcga-study"><i class="fa fa-check"></i><b>6.2</b> The <code>breast.TCGA</code> study</a></li>
<li class="chapter" data-level="6.3" data-path="diablo.html"><a href="diablo.html#principle-of-diablo"><i class="fa fa-check"></i><b>6.3</b> Principle of DIABLO</a></li>
<li class="chapter" data-level="6.4" data-path="diablo.html"><a href="diablo.html#inputs-and-outputs-2"><i class="fa fa-check"></i><b>6.4</b> Inputs and outputs</a></li>
<li class="chapter" data-level="6.5" data-path="diablo.html"><a href="diablo.html#set-up-the-data-2"><i class="fa fa-check"></i><b>6.5</b> Set up the data</a></li>
<li class="chapter" data-level="6.6" data-path="diablo.html"><a href="diablo.html#quick-start-3"><i class="fa fa-check"></i><b>6.6</b> Quick start</a></li>
<li class="chapter" data-level="6.7" data-path="diablo.html"><a href="diablo.html#to-go-further-1"><i class="fa fa-check"></i><b>6.7</b> To go further</a><ul>
<li class="chapter" data-level="6.7.1" data-path="diablo.html"><a href="diablo.html#diablo:plotIndiv"><i class="fa fa-check"></i><b>6.7.1</b> Customize sample plots</a></li>
<li class="chapter" data-level="6.7.2" data-path="diablo.html"><a href="diablo.html#diablo:plotVar"><i class="fa fa-check"></i><b>6.7.2</b> Customize variable plots</a></li>
<li class="chapter" data-level="6.7.3" data-path="diablo.html"><a href="diablo.html#other-useful-plots-for-data-integration-1"><i class="fa fa-check"></i><b>6.7.3</b> Other useful plots for data integration</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="diablo.html"><a href="diablo.html#numerical-outputs"><i class="fa fa-check"></i><b>6.8</b> Numerical outputs</a><ul>
<li class="chapter" data-level="6.8.1" data-path="diablo.html"><a href="diablo.html#classification-performance"><i class="fa fa-check"></i><b>6.8.1</b> Classification performance</a></li>
<li class="chapter" data-level="6.8.2" data-path="diablo.html"><a href="diablo.html#auc"><i class="fa fa-check"></i><b>6.8.2</b> AUC</a></li>
<li class="chapter" data-level="6.8.3" data-path="diablo.html"><a href="diablo.html#tuning-parameters-1"><i class="fa fa-check"></i><b>6.8.3</b> Tuning parameters</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="diablo.html"><a href="diablo.html#additional-resources-3"><i class="fa fa-check"></i><b>6.9</b> Additional resources</a></li>
<li class="chapter" data-level="6.10" data-path="diablo.html"><a href="diablo.html#faq-3"><i class="fa fa-check"></i><b>6.10</b> FAQ</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="session-information.html"><a href="session-information.html"><i class="fa fa-check"></i><b>7</b> Session Information</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">mixOmics vignette</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="plsda" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> PLS - Discriminant Analysis (PLS-DA)</h1>
<p><img src="Figures/overview-PLSDA-1.png" width="50%" style="display: block; margin: auto;" /></p>
<div id="biological-question-2" class="section level2">
<h2><span class="header-section-number">4.1</span> Biological question</h2>
<p><span style="color:blue"> <em>I am analysing a single data set (e.g. transcriptomics data) and I would like to classify my samples into known groups and predict the class of new samples. In addition, I am interested in identifying the key variables that drive such discrimination.</em> </span></p>
</div>
<div id="the-srbct-study" class="section level2">
<h2><span class="header-section-number">4.2</span> The <code>srbct</code> study</h2>
<p>The data are directly available in a processed and normalised format from the package. The Small Round Blue Cell Tumours (SRBCT) dataset from <span class="citation">(Khan et al. <a href="#ref-Kha01">2001</a>)</span> includes the expression levels of 2,308 genes measured on 63 samples. The samples are classified into four classes as follows: 8 Burkitt Lymphoma (BL), 23 Ewing Sarcoma (EWS), 12 neuroblastoma (NB), and 20 rhabdomyosarcoma (RMS).</p>
<p>The srbct dataset contains the following:</p>
<p><strong>$gene:</strong> a data frame with 63 rows and 2308 columns. The expression levels of 2,308 genes in 63 subjects.</p>
<p><strong>$class:</strong> a class vector containing the class tumour of each individual (4 classes in total).</p>
<p><strong>$gene.name:</strong> a data frame with 2,308 rows and 2 columns containing further information on the genes.</p>
<p>More details can be found in <code>?srbct</code>.</p>
<p>To illustrate PLS-DA, we will analyse the gene expression levels of <code>srbct$gene</code> to discriminate the 4 groups of tumours.</p>
</div>
<div id="principle-of-sparse-pls-da" class="section level2">
<h2><span class="header-section-number">4.3</span> Principle of sparse PLS-DA</h2>
<p>Although Partial Least Squares was not originally designed for classification and discrimination problems, it has often been used for that purpose <span class="citation">(Nguyen and Rocke <a href="#ref-Ngu02a">2002</a>; Tan et al. <a href="#ref-Tan04">2004</a>)</span>. The response matrix <code>Y</code> is qualitative and is internally recoded as a dummy block matrix that records the membership of each observation, i.e. each of the response categories are coded via an indicator variable (see <span class="citation">(Florian Rohart et al. <a href="#ref-mixomics">2017</a>)</span> Suppl. Information S1 for an illustration). The PLS regression (now PLS-DA) is then run as if Y was a continuous matrix. This PLS classification trick works well in practice, as demonstrated in many references <span class="citation">(Barker and Rayens <a href="#ref-Bar03">2003</a>; Nguyen and Rocke <a href="#ref-Ngu02a">2002</a>; Boulesteix and Strimmer <a href="#ref-Bou07">2007</a>; Chung and Keles <a href="#ref-Chung10">2010</a>)</span>.</p>
<p>Sparse PLS-DA <span class="citation">(Lê Cao, Boitard, and Besse <a href="#ref-Lec11">2011</a>)</span> performs variable selection and classification in a one step procedure. sPLS-DA is a special case of sparse PLS described later in <a href="pls.html#pls">5</a>, where <span class="math inline">\(\ell_1\)</span> penalization is applied on the loading vectors associated to the X data set.</p>
</div>
<div id="inputs-and-outputs" class="section level2">
<h2><span class="header-section-number">4.4</span> Inputs and outputs</h2>
<p>We use the following data input matrices: <code>X</code> is a <span class="math inline">\(n \times p\)</span> data matrix, <code>Y</code> is a factor vector of length <span class="math inline">\(n\)</span> that indicates the class of each sample, and <span class="math inline">\(Y^*\)</span> is the associated dummy matrix (<span class="math inline">\(n \times K\)</span>) with <span class="math inline">\(n\)</span> the number of samples (individuals), <span class="math inline">\(p\)</span> the number of variables and <span class="math inline">\(K\)</span> the number of classes. PLS-DA main outputs are:</p>
<ul>
<li><p>A <strong>set of components</strong>, also called latent variables. There are as many components as the chosen <em>dimension</em> of the PLS-DA model.</p></li>
<li><p>A <strong>set of loading vectors</strong>, which are coefficients assigned to each variable to define each component. Those coefficients indicate the importance of each variable in PLS-DA. Importantly, each loading vector is associated to a particular component. Loading vectors are obtained so that the covariance between a linear combination of the variables from X (the X-component) and the factor of interest Y (the <span class="math inline">\(Y^*\)</span>-component) is maximised.</p></li>
<li><p>A <strong>list of selected variables</strong> from <code>X</code> and associated to each component if sPLS-DA is applied.</p></li>
</ul>
</div>
<div id="set-up-the-data" class="section level2">
<h2><span class="header-section-number">4.5</span> Set up the data</h2>
<p>We first load the data from the package. See <a href="start.html#start:upload">2.2</a> to upload your own data.</p>
<p>We will mainly focus on sparse PLS-DA that is more suited for large biological data sets where the aim is to identify molecular signatures, as well as classifying samples. We first set up the data as <code>X</code> expression matrix and <code>Y</code> as a factor indicating the class membership of each sample. We also check that the dimensions are correct and match:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mixOmics)
<span class="kw">data</span>(srbct)
X &lt;-<span class="st"> </span>srbct<span class="op">$</span>gene
Y &lt;-<span class="st"> </span>srbct<span class="op">$</span>class 
<span class="kw">summary</span>(Y)</code></pre></div>
<pre><code>## EWS  BL  NB RMS 
##  23   8  12  20</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dim</span>(X); <span class="kw">length</span>(Y)</code></pre></div>
<pre><code>## [1]   63 2308</code></pre>
<pre><code>## [1] 63</code></pre>
</div>
<div id="quick-start-1" class="section level2">
<h2><span class="header-section-number">4.6</span> Quick start</h2>
<p>For a quick start we arbitrarily set the number of variables to select to 50 on each of the 3 components of PLS-DA (see section <a href="plsda.html#tuning:sPLSDA">4.7.5</a> for tuning these values).</p>
<p>As PLS-DA is a supervised method, the sample plot automatically displays the group membership of each sample. We can observe a clear discrimination between the BL samples and the others on the first component (x-axis), and EWS vs the others on the second component (y-axis). Remember that this discrimination spanned by the first two PLS-DA components is obtained based on a subset of 100 variables (50 selected on each component).</p>
<p>From the <code>plotIndiv</code> the axis labels indicate the amount of variation explained per component. Note that the interpretation of this amount is <em>not</em> the same as in PCA. In PLS-DA, the aim is to maximise the covariance between <code>X</code> and <code>Y</code>, not only the variance of <code>X</code> as it is the case in PCA!</p>
<p>If you were to run <code>splsda</code> with this minimal code, you would be using the following default values:</p>
<ul>
<li><code>ncomp = 2</code>: the first two PLS components are calculated and are used for graphical outputs;</li>
<li><code>scale = TRUE</code>: data are scaled (variance = 1, strongly advised here);</li>
<li><code>mode = &quot;regression&quot;</code>: by default a PLS regression mode should be used.</li>
</ul>
<p>PLS-DA without variable selection can be performed as:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MyResult.plsda &lt;-<span class="st"> </span><span class="kw">plsda</span>(X,Y) <span class="co"># 1 Run the method</span>
<span class="kw">plotIndiv</span>(MyResult.plsda)    <span class="co"># 2 Plot the samples</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plotVar</span>(MyResult.plsda)      <span class="co"># 3 Plot the variables</span></code></pre></div>
</div>
<div id="plsda-tgf" class="section level2">
<h2><span class="header-section-number">4.7</span> To go further</h2>
<div id="splsda:plotIndiv" class="section level3">
<h3><span class="header-section-number">4.7.1</span> Customize sample plots</h3>
<p>The sample plots can be improved in various ways. First, if the names of the samples are not meaningful at this stage, they can be replaced by symbols (<code>ind.names=TRUE</code>). Confidence ellipses can be plotted for each sample (<code>ellipse = TRUE</code>, confidence level set to 95% by default, see the argument <code>ellipse.level</code>), Additionally, a star plot displays arrows from each group centroid towards each individual sample (<code>star = TRUE</code>). A 3D plot is also available, see <code>plotIndiv</code> for more details.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plotIndiv</span>(MyResult.splsda, <span class="dt">ind.names =</span> <span class="ot">FALSE</span>, <span class="dt">legend=</span><span class="ot">TRUE</span>,
          <span class="dt">ellipse =</span> <span class="ot">TRUE</span>, <span class="dt">star =</span> <span class="ot">TRUE</span>, <span class="dt">title =</span> <span class="st">&#39;sPLS-DA on SRBCT&#39;</span>,
          <span class="dt">X.label =</span> <span class="st">&#39;PLS-DA 1&#39;</span>, <span class="dt">Y.label =</span> <span class="st">&#39;PLS-DA 2&#39;</span>)</code></pre></div>
<p><img src="Figures/unnamed-chunk-4-1.png" width="50%" style="display: block; margin: auto;" /></p>
</div>
<div id="customize-variable-plots" class="section level3">
<h3><span class="header-section-number">4.7.2</span> Customize variable plots</h3>
<p>The name of the variables can be set to FALSE (<code>var.names=FALSE</code>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plotVar</span>(MyResult.splsda, <span class="dt">var.names=</span><span class="ot">FALSE</span>)</code></pre></div>
<p><img src="Figures/unnamed-chunk-5-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>In addition, if we had used the non sparse version of PLS-DA, a cut-off can be set to display only the variables that mostly contribute to the definition of each component. Those variables should be located towards the circle of radius 1, far from the centre.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plotVar</span>(MyResult.plsda, <span class="dt">cutoff=</span><span class="fl">0.7</span>)</code></pre></div>
<p><img src="Figures/unnamed-chunk-6-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>In this particular case, no variable selection was performed. Only the display was altered to show a subset of variables.</p>
</div>
<div id="other-useful-plots-1" class="section level3">
<h3><span class="header-section-number">4.7.3</span> Other useful plots</h3>
<div id="background-prediction" class="section level4">
<h4><span class="header-section-number">4.7.3.1</span> Background prediction</h4>
<p>A ‘prediction’ background can be added to the sample plot by calculating a background surface first, before overlaying the sample plot. See <code>?background.predict</code> for more details. More details about prediction, prediction distances can be found in <span class="citation">(Florian Rohart et al. <a href="#ref-mixomics">2017</a>)</span> in the Suppl. Information.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">background &lt;-<span class="st"> </span><span class="kw">background.predict</span>(MyResult.splsda, <span class="dt">comp.predicted=</span><span class="dv">2</span>,
                                <span class="dt">dist =</span> <span class="st">&quot;max.dist&quot;</span>) 
<span class="kw">plotIndiv</span>(MyResult.splsda, <span class="dt">comp =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>, <span class="dt">group =</span> srbct<span class="op">$</span>class,
          <span class="dt">ind.names =</span> <span class="ot">FALSE</span>, <span class="dt">title =</span> <span class="st">&quot;Maximum distance&quot;</span>,
          <span class="dt">legend =</span> <span class="ot">TRUE</span>,  <span class="dt">background =</span> background)</code></pre></div>
<p><img src="Figures/unnamed-chunk-7-1.png" width="50%" style="display: block; margin: auto;" /></p>
</div>
<div id="roc" class="section level4">
<h4><span class="header-section-number">4.7.3.2</span> ROC</h4>
<p>As PLS-DA acts as a classifier, we can plot a ROC Curve to complement the sPLS-DA classification performance results detailed in <a href="plsda.html#tuning:sPLSDA">4.7.5</a>. The AUC is calculated from training cross-validation sets and averaged. Note however that ROC and AUC criteria may not be particularly insightful, or may not be in full agreement with the PLSDA performance, as the prediction threshold in PLS-DA is based on specified distance as described in <span class="citation">(Florian Rohart et al. <a href="#ref-mixomics">2017</a>)</span>.</p>
<p><img src="Figures/unnamed-chunk-8-1.png" width="50%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="variable-selection-outputs" class="section level3">
<h3><span class="header-section-number">4.7.4</span> Variable selection outputs</h3>
<p>First, note that the number of variables to select on each component does not need to be identical on each component, for example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MyResult.splsda2 &lt;-<span class="st"> </span><span class="kw">splsda</span>(X,Y, <span class="dt">ncomp=</span><span class="dv">3</span>, <span class="dt">keepX=</span><span class="kw">c</span>(<span class="dv">15</span>,<span class="dv">10</span>,<span class="dv">5</span>))</code></pre></div>
<p>Selected variables are listed in the <code>selectVar</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">selectVar</span>(MyResult.splsda2, <span class="dt">comp=</span><span class="dv">1</span>)<span class="op">$</span>value</code></pre></div>
<pre><code>##        value.var
## g123  0.53516982
## g846  0.41271455
## g335  0.30309695
## g1606 0.30194141
## g836  0.29365241
## g783  0.26329876
## g758  0.25826903
## g1386 0.23702577
## g1158 0.15283961
## g585  0.13838913
## g589  0.12738682
## g1387 0.12202390
## g1884 0.08458869
## g1295 0.03150351
## g1036 0.00224886</code></pre>
<p>and can be visualised in <code>plotLoadings</code> with the arguments <code>contrib = 'max'</code> that is going to assign to each variable bar the sample group colour for which the mean (<code>method = 'mean'</code>) is maximum. See <code>example(plotLoadings)</code> for other options (e.g. min, median)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plotLoadings</span>(MyResult.splsda2, <span class="dt">contrib =</span> <span class="st">&#39;max&#39;</span>, <span class="dt">method =</span> <span class="st">&#39;mean&#39;</span>)</code></pre></div>
<p><img src="Figures/unnamed-chunk-11-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Interestingly from this plot, we can see that all selected variables on component 1 are highly expressed in the BL (orange) class. Setting <code>contrib = 'min'</code> would highlight that those variables are lowly expressed in the NB grey class, which makes sense when we look at the sample plot.</p>
<p>Since 4 classes are being discriminated here, samples plots in 3d may help interpretation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plotIndiv</span>(MyResult.splsda2, <span class="dt">style=</span><span class="st">&quot;3d&quot;</span>)</code></pre></div>
</div>
<div id="tuning:sPLSDA" class="section level3">
<h3><span class="header-section-number">4.7.5</span> Tuning parameters and numerical outputs</h3>
<p>For this set of methods, three parameters need to be chosen:</p>
<p>1 - The number of components to retain <code>ncomp</code>. The rule of thumb is usually <span class="math inline">\(K - 1\)</span> where <span class="math inline">\(K\)</span> is the number of classes, but it is worth testing a few extra components.</p>
<p>2 - The number of variables <code>keepX</code> to select on each component for sparse PLS-DA,</p>
<p>3 - The prediction distance to evaluate the classification and prediction performance of PLS-DA.</p>
<p>For <strong>item 1</strong>, the <code>perf</code> evaluates the performance of PLS-DA for a large number of components, using repeated k-fold cross-validation. For example here we use 3-fold CV repeated 10 times (note that we advise to use at least 50 repeats, and choose the number of folds that are appropriate for the sample size of the data set):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MyResult.plsda2 &lt;-<span class="st"> </span><span class="kw">plsda</span>(X,Y, <span class="dt">ncomp=</span><span class="dv">10</span>)
<span class="kw">set.seed</span>(<span class="dv">30</span>) <span class="co"># for reproducbility in this vignette, otherwise increase nrepeat</span>
MyPerf.plsda &lt;-<span class="st"> </span><span class="kw">perf</span>(MyResult.plsda2, <span class="dt">validation =</span> <span class="st">&quot;Mfold&quot;</span>, <span class="dt">folds =</span> <span class="dv">3</span>, 
                  <span class="dt">progressBar =</span> <span class="ot">FALSE</span>, <span class="dt">nrepeat =</span> <span class="dv">10</span>) <span class="co"># we suggest nrepeat = 50</span>

<span class="kw">plot</span>(MyPerf.plsda, <span class="dt">col =</span> <span class="kw">color.mixo</span>(<span class="dv">5</span><span class="op">:</span><span class="dv">7</span>), <span class="dt">sd =</span> <span class="ot">TRUE</span>, <span class="dt">legend.position =</span> <span class="st">&quot;horizontal&quot;</span>)</code></pre></div>
<p><img src="Figures/unnamed-chunk-13-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>The plot outputs the classification error rate, or <em>Balanced</em> classification error rate when the number of samples per group is unbalanced, the standard deviation according to three prediction distances. Here we can see that for the BER and the maximum distance, the best performance (i.e. low error rate) seems to be achieved for <code>ncomp = 3</code>.</p>
<p>In addition for <strong>item 3</strong> for PLS-DA, the numerical outputs listed here can be reported as performance measures:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MyPerf.plsda</code></pre></div>
<pre><code>## 
## Call:
##  perf.plsda(object = MyResult.plsda2, validation = &quot;Mfold&quot;, folds = 3, nrepeat = 10, progressBar = FALSE) 
## 
##  Main numerical outputs: 
##  -------------------- 
##  Error rate (overall or BER) for each component and for each distance: see object$error.rate 
##  Error rate per class, for each component and for each distance: see object$error.rate.class 
##  Prediction values for each component: see object$predict 
##  Classification of each sample, for each component and for each distance: see object$class 
##  AUC values: see object$auc if auc = TRUE 
## 
##  Visualisation Functions: 
##  -------------------- 
##  plot</code></pre>
<p>Regarding <strong>item 2</strong>, we now use <code>tune.splsda</code> to assess the optimal number of variables to select on each component. We first set up a grid of <code>keepX</code> values that will be assessed on each component, one component at a time. Similar to above we run 3-fold CV repeated 10 times with a maximum distance prediction defined as above.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">list.keepX &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">5</span><span class="op">:</span><span class="dv">10</span>,  <span class="kw">seq</span>(<span class="dv">20</span>, <span class="dv">100</span>, <span class="dv">10</span>))
list.keepX <span class="co"># to output the grid of values tested</span></code></pre></div>
<pre><code>##  [1]   5   6   7   8   9  10  20  30  40  50  60  70  80  90 100</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">30</span>) <span class="co"># for reproducbility in this vignette, otherwise increase nrepeat</span>
tune.splsda.srbct &lt;-<span class="st"> </span><span class="kw">tune.splsda</span>(X, Y, <span class="dt">ncomp =</span> <span class="dv">3</span>, <span class="co"># we suggest to push ncomp a bit more, e.g. 4</span>
                                 <span class="dt">validation =</span> <span class="st">&#39;Mfold&#39;</span>,
                                 <span class="dt">folds =</span> <span class="dv">3</span>, <span class="dt">dist =</span> <span class="st">&#39;max.dist&#39;</span>, <span class="dt">progressBar =</span> <span class="ot">FALSE</span>,
                                 <span class="dt">measure =</span> <span class="st">&quot;BER&quot;</span>, <span class="dt">test.keepX =</span> list.keepX,
                                 <span class="dt">nrepeat =</span> <span class="dv">10</span>)   <span class="co"># we suggest nrepeat = 50</span></code></pre></div>
<p>We can then extract the classification error rate averaged across all folds and repeats for each tested <code>keepX</code> value, the optimal number of components (see <code>?tune.splsda</code> for more details), the optimal number of variables to select per component which is summarised in a plot where the diamond indicated the optimal <code>keepX</code> value:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">error &lt;-<span class="st"> </span>tune.splsda.srbct<span class="op">$</span>error.rate
ncomp &lt;-<span class="st"> </span>tune.splsda.srbct<span class="op">$</span>choice.ncomp<span class="op">$</span>ncomp <span class="co"># optimal number of components based on t-tests on the error rate</span>
ncomp</code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">select.keepX &lt;-<span class="st"> </span>tune.splsda.srbct<span class="op">$</span>choice.keepX[<span class="dv">1</span><span class="op">:</span>ncomp]  <span class="co"># optimal number of variables to select</span>
select.keepX</code></pre></div>
<pre><code>## comp1 comp2 comp3 
##    50    50    70</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(tune.splsda.srbct, <span class="dt">col =</span> <span class="kw">color.jet</span>(ncomp))</code></pre></div>
<p><img src="Figures/unnamed-chunk-16-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Based on those tuning results, we can run our final and tuned sPLS-DA model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MyResult.splsda.final &lt;-<span class="st"> </span><span class="kw">splsda</span>(X, Y, <span class="dt">ncomp =</span> ncomp, <span class="dt">keepX =</span> select.keepX)
<span class="kw">plotIndiv</span>(MyResult.splsda.final, <span class="dt">ind.names =</span> <span class="ot">FALSE</span>, <span class="dt">legend=</span><span class="ot">TRUE</span>,
          <span class="dt">ellipse =</span> <span class="ot">TRUE</span>, <span class="dt">title=</span><span class="st">&quot;SPLS-DA, Final result&quot;</span>)</code></pre></div>
<p>Additionally we can run <code>perf</code> for the final performance of the sPLS-DA model. Also note that <code>perf</code> will output <code>features</code> that lists the frequency of selection of the variables across the different folds and different repeats. This is a useful output to assess the confidence of your final variable selection, see a more <a href="http://mixomics.org/case-studies/splsda-srbct/">detailed example here</a>.</p>
</div>
</div>
<div id="additional-resources-1" class="section level2">
<h2><span class="header-section-number">4.8</span> Additional resources</h2>
<p>Additional examples are provided in <code>example(splsda)</code> and in our case studies on our <a href="http://www.mixomics.org">website</a> in the <strong>Methods</strong> and <strong>Case studies</strong> sections, and in particular <a href="http://mixomics.org/case-studies/splsda-srbct/">here</a>. Also have a look at <span class="citation">(Lê Cao, Boitard, and Besse <a href="#ref-Lec11">2011</a>)</span></p>
</div>
<div id="faq-1" class="section level2">
<h2><span class="header-section-number">4.9</span> FAQ</h2>
<ul>
<li>Can I discriminate more than two groups of samples (multiclass classification)?
<ul>
<li>Yes, this is one of the advantage of PLS-DA, see this example above</li>
</ul></li>
<li>Can I have a hierarchy between two factors (e.g. diet nested into genotype)?
<ul>
<li>Unfortunately no, sparse PLS-DA only allows to discriminate all groups at once (i.e. 4 x 2 groups when there are 4 diets and 2 genotypes)</li>
</ul></li>
<li>Can I have missing values in my data?
<ul>
<li>Yes in the X data set, but you won’t be able to do any prediction (i.e. <code>tune, perf, predict</code>)</li>
<li>No in the Y factor</li>
</ul></li>
</ul>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Kha01">
<p>Khan, Javed, Jun S Wei, Markus Ringner, Lao H Saal, Marc Ladanyi, Frank Westermann, Frank Berthold, et al. 2001. “Classification and Diagnostic Prediction of Cancers Using Gene Expression Profiling and Artificial Neural Networks.” <em>Nature Medicine</em> 7 (6). Nature Publishing Group: 673–79.</p>
</div>
<div id="ref-Ngu02a">
<p>Nguyen, D.V., and D.M. Rocke. 2002. “Tumor classification by partial least squares using microarray gene expression data.” <em>Bioinformatics</em> 18 (1). Oxford Univ Press: 39.</p>
</div>
<div id="ref-Tan04">
<p>Tan, Y., L. Shi, W. Tong, GT Gene Hwang, and C. Wang. 2004. “Multi-class tumor classification by discriminant partial least squares using microarray gene expression data and assessment of classification models.” <em>Computational Biology and Chemistry</em> 28 (3). Elsevier: 235–43.</p>
</div>
<div id="ref-mixomics">
<p>Rohart, Florian, Benoit Gautier, Amrit Singh, and Kim-Anh Le Cao. 2017. “MixOmics: An R Package for ‘Omics Feature Selection and Multiple Data Integration.” <em>PLoS Computational Biology</em> 13 (11). Cold Spring Harbor Labs Journals.</p>
</div>
<div id="ref-Bar03">
<p>Barker, Matthew, and William Rayens. 2003. “Partial Least Squares for Discrimination.” <em>Journal of Chemometrics</em> 17 (3). Wiley Online Library: 166–73.</p>
</div>
<div id="ref-Bou07">
<p>Boulesteix, A.L., and K. Strimmer. 2007. “Partial least squares: a versatile tool for the analysis of high-dimensional genomic data.” <em>Briefings in Bioinformatics</em> 8 (1). Oxford Univ Press: 32.</p>
</div>
<div id="ref-Chung10">
<p>Chung, D., and S. Keles. 2010. “Sparse Partial Least Squares Classification for High Dimensional Data.” <em>Statistical Applications in Genetics and Molecular Biology</em> 9 (1). bepress: 17.</p>
</div>
<div id="ref-Lec11">
<p>Lê Cao, Kim-Anh, Simon Boitard, and Philippe Besse. 2011. “Sparse PLS Discriminant Analysis: Biologically Relevant Feature Selection and Graphical Displays for Multiclass Problems.” <em>BMC Bioinformatics</em> 12 (1). BioMed Central Ltd: 253.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="pca.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="pls.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/04-PLSDA.Rmd",
"text": "Edit"
},
"download": ["Vignette-mixOmics.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
